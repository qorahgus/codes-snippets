{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8f5fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PyAudio Example: Play a wave file.\"\"\"\n",
    "import os, sys\n",
    "from struct import pack, unpack\n",
    "import numpy as np\n",
    "from scipy.fft import fft\n",
    "from scipy.io import wavfile as wav\n",
    "import matplotlib.pyplot as plt\n",
    "import pyaudio\n",
    "import wave\n",
    "from queue import Queue\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bb6e297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!            \n"
     ]
    }
   ],
   "source": [
    "# Timer\n",
    "import time\n",
    "\n",
    "for remaining in range(10, 0, -1):\n",
    "    sys.stdout.write(\"\\r\")\n",
    "    sys.stdout.write(\"{:2d} seconds remaining.\".format(remaining)) \n",
    "    sys.stdout.flush()\n",
    "    time.sleep(1)\n",
    "\n",
    "sys.stdout.write(\"\\rComplete!            \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96cb0bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting channel 1 out of 2 channels, 16-bit depth\n",
      "channel : 0, nch : 2, sdata : 33661440\n",
      "Extracting channel 2 out of 2 channels, 16-bit depth\n",
      "channel : 1, nch : 2, sdata : 33661440\n"
     ]
    }
   ],
   "source": [
    "# # Convert stereo to mono\n",
    "# def save_wav_channel(fn, wav, channel):\n",
    "#     '''\n",
    "#     Take Wave_read object as an input and save one of its\n",
    "#     channels into a separate .wav file.\n",
    "#     '''\n",
    "#     # Read data\n",
    "#     nch   = wav.getnchannels()\n",
    "#     depth = wav.getsampwidth()\n",
    "#     wav.setpos(0)\n",
    "#     sdata = wav.readframes(wav.getnframes())\n",
    "\n",
    "#     # Extract channel data (24-bit data not supported)\n",
    "#     typ = { 1: np.uint8, 2: np.uint16, 4: np.uint32 }.get(depth)\n",
    "#     if not typ:\n",
    "#         raise ValueError(\"sample width {} not supported\".format(depth))\n",
    "#     if channel >= nch:\n",
    "#         raise ValueError(\"cannot extract channel {} out of {}\".format(channel+1, nch))\n",
    "#     print (\"Extracting channel {} out of {} channels, {}-bit depth\".format(channel+1, nch, depth*8))\n",
    "#     data = np.frombuffer(sdata, dtype=typ)\n",
    "# #     data = np.fromstring(sdata, dtype=typ)\n",
    "#     print(f\"channel : {channel}, nch : {nch}, sdata : {len(sdata)}\")\n",
    "#     ch_data = data[channel::nch]\n",
    "\n",
    "#     # Save channel to a separate file\n",
    "#     outwav = wave.open(fn, 'w')\n",
    "#     outwav.setparams(wav.getparams())\n",
    "#     outwav.setnchannels(1)\n",
    "#     outwav.writeframes(ch_data.tobytes())\n",
    "# #     outwav.writeframes(ch_data.tostring())\n",
    "#     outwav.close()\n",
    "\n",
    "# WAV_FILENAME = \"김수철-08-못다핀꽃한송이.wav\"   \n",
    "# basename = WAV_FILENAME.split('.')\n",
    "# wav = wave.open(WAV_FILENAME)\n",
    "# save_wav_channel(basename[0] + 'ch1.wav', wav, 0)\n",
    "# save_wav_channel(basename[0] +'ch2.wav', wav, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adeba255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_wave_params(nchannels=1, sampwidth=2, framerate=44100, nframes=8415360, comptype='NONE', compname='not compressed')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf = wave.open(\"김수철-08-못다핀꽃한송이ch1.wav\", 'rb')\n",
    "pa = pyaudio.PyAudio()\n",
    "stream = pa.open(format=pa.get_format_from_width(wf.getsampwidth()),\n",
    "                channels=wf.getnchannels(),\n",
    "                rate=wf.getframerate(),\n",
    "                input=True,\n",
    "                output=True)\n",
    "wf.getparams()\n",
    "# pyaudio.get_portaudio_version()\n",
    "# pa.get_default_host_api_info()\n",
    "# wf.getsampwidth()\n",
    "# pa.get_format_from_width()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a712272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048 => b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
      "2048 => (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "CHUNK = 1024    # read buffer size\n",
    "\n",
    "raw_samples = wf.readframes(CHUNK)\n",
    "print(len(raw_samples), '=>', raw_samples[0:20])\n",
    "int_samples = unpack(str(2*CHUNK)+'b', raw_samples)\n",
    "print(len(int_samples), '=>', int_samples[0:20])\n",
    "\n",
    "# fig, t_ax = plt.subplots()\n",
    "# t_ax.plot(int_samples)\n",
    "# plt.show()\n",
    "\n",
    "# try:\n",
    "#     while True:\n",
    "#         raw_samples = wf.readframes(CHUNK)\n",
    "#         int_samples = unpack(str(4*CHUNK)+'B', wf.readframes(CHUNK))\n",
    "#         fig.canvas.draw()\n",
    "#         fig.canvas.flush_events()\n",
    "# except KeyboardInterrupt:\n",
    "#     # stop stream (4)\n",
    "#     stream.stop_stream()\n",
    "#     stream.close()\n",
    "#     # close PyAudio (5)\n",
    "#     p.terminate()\n",
    "#     sys.exit(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5124ff0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8415360 => [0 0 0 0 0 0 0 0 0 0]\n",
      "1024 => [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "rate, data = wav.read('김수철-08-못다핀꽃한송이ch1.wav')\n",
    "chunk = np.frombuffer(data, count=CHUNK, dtype='int16')\n",
    "print(len(data), '=>', data[0:10])\n",
    "print(len(chunk), '=>', chunk[0:10])\n",
    "# print(data.min(), data.max(), data.dtype, data.shape[0]/rate)\n",
    "\n",
    "# plt.plot(data[CHUNK:CHUNK*2])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fece6c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8415360"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.linspace(0, round((data.shape[0]/rate)), data.shape[0], endpoint=True)\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d9647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSP",
   "language": "python",
   "name": "dsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
